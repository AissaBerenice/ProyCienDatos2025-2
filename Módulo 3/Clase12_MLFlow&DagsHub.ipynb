{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones comunes para un ambiente de `MLflow Tracking`.\n",
    "![](https://mlflow.org/docs/3.0.1/assets/images/tracking-setup-overview-3d8cfd511355d9379328d69573763331.png)\n",
    "\n",
    "### Escenario 2\n",
    "```python\n",
    "# set mlflow tracking uri\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "```\n",
    "\n",
    "### Escenario 3\n",
    "MLFlow remoto\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('url/remote/server')\n",
    "```\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Escenario | 1. Localhost (por defecto) | 2. Seguimiento local con base de datos local | 3. Seguimiento remoto con **MLflow Tracking Server** |\n",
    "|------------|-----------------------------|-----------------------------------------------|------------------------------------------------------|\n",
    "| **Caso de uso** | Desarrollo individual | Desarrollo individual | Desarrollo en equipo |\n",
    "| **Descripción** | Por defecto, MLflow guarda los metadatos y artefactos de cada ejecución en un directorio local llamado `mlruns`. Es la forma más simple de comenzar con MLflow Tracking, sin necesidad de configurar servidores, bases de datos o almacenamiento externos. | El cliente de MLflow puede conectarse con una base de datos compatible con SQLAlchemy (por ejemplo, SQLite, PostgreSQL o MySQL) como *backend*. Guardar los metadatos en una base de datos permite una gestión más limpia de los datos de los experimentos, evitando el esfuerzo de configurar un servidor. | El servidor de seguimiento de MLflow puede configurarse con un *proxy* HTTP para artefactos, redirigiendo las solicitudes de artefactos a través del servidor para almacenar y recuperar sin interactuar directamente con los servicios de almacenamiento subyacentes. Es especialmente útil para entornos de trabajo en equipo, donde se necesita almacenar artefactos y metadatos de experimentos en una ubicación compartida con control de acceso adecuado. |\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## `MLflow`: Beneficios\n",
    "* El `Tracking server` puede ser fácilmente desplegado en la nube\n",
    "* Compartir experimentos con otros Data Scientists\n",
    "* Colaborar con otros para construir y desplegar modelos\n",
    "* Dar más visibilidad de los esfuerzos del equipo de Data Science.\n",
    "\n",
    "## `MLflow`: Problemas cuando se ejecutan servidores remotos compartidos\n",
    "* Seguridad:\n",
    "    * Restringir el acceso al server (por ejemplo a través de una VPN)\n",
    "* Isolation:\n",
    "    * Definir un estándar para nombrar experimentos, modelos y un conjunto de tags predeterminados.\n",
    "    * Restringir el acceso a los artefactos  \n",
    "\n",
    "## `MLflow`: Limitaciones\n",
    "* **Autenticación y Usuarios:** La versión open source de `MLflow` no provee ningún tipo de autenticación\n",
    "* **Versionamiento de datos** \n",
    "    * Para asegurar total reproducibilidad, necesitamos versionar los datos que se usan para entrenar el modelo.\n",
    "    * `MLflow` no provee una solución para eso, pero hay maneras de mitigarlo\n",
    "* **Monitoreo del modelo y datos:** Veremos la herramienta adecuada para este fin "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DagsHub\n",
    " <div style=\"text-align:center\">\n",
    "    <img src=\"https://user-images.githubusercontent.com/611655/181510038-e38f4001-c304-411e-8f45-f71554eb9763.png\" alt=\"DagsHub Logo\">\n",
    "</div>\n",
    "\n",
    "## Introducción:\n",
    "DagsHub es una plataforma revolucionaria que se describe como el \"GitHub para el aprendizaje automático\". Permite a los científicos de datos y desarrolladores de aprendizaje automático gestionar y colaborar en sus proyectos de manera eficiente, asegurando la reproducibilidad y el control de versiones.\n",
    "\n",
    "## Características Clave:\n",
    "1. **Control de Versiones**: Realiza un seguimiento de los cambios en los datos, el código y los modelos, garantizando un historial completo de tu proyecto de aprendizaje automático.\n",
    "2. **Colaboración**: Facilita la colaboración dentro de los equipos al permitir que varios usuarios trabajen en el mismo proyecto manteniendo el historial de versiones.\n",
    "3. **Versionado de Datos**: Realiza un seguimiento de las versiones de los datos, lo que facilita la reproducción de experimentos y el intercambio de conjuntos de datos.\n",
    "4. **Reproducibilidad**: Asegura que los experimentos se puedan replicar con el mismo código, datos y entorno.\n",
    "5. **Interfaz Web**: Ofrece una interfaz web intuitiva para organizar y gestionar proyectos de aprendizaje automático.\n",
    "6. **Repositorios Públicos y Privados**: Ofrece tanto repositorios públicos como privados para compartir proyectos de manera abierta o segura.\n",
    "7. **Seguimiento de Experimentos**: Registra todos los detalles de los experimentos de aprendizaje automático, lo que facilita el análisis y la comparación de resultados.\n",
    "8. **Integración**: Se integra fácilmente con herramientas y formatos de código abierto populares, como Jupyter notebooks y Git.\n",
    "9. **Organización de Proyectos**: Proporciona herramientas para mantener estructurado y bien documentado tu proyecto de aprendizaje automático.\n",
    "\n",
    "\n",
    "## Dagshub\n",
    "\n",
    "1. Creamos una cuenta [aquí](https://dagshub.com/user/sign_up). Se puede asociar con la cuenta de GitHub.\n",
    "2. Cambiar contraseña.\n",
    "3. Crear un primer repositorio."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Actividad\n",
    "Vamos a prepara el ambiente de trabajo para la siguiente clase:\n",
    "\n",
    "1. Vinculamos el repositorio `nyc-taxi-time-prediction-2025` a nuestra cuenta de `Dagshub`\n",
    "4. Crear una branch `dagshub-experiments`\n",
    "5. Crear un directorio `experiments` en la carpeta raíz del proyecto\n",
    "6. Crer un `jupyter-notebook` dentro de dicho directorio con el nombre `01-daghub_model_experiments.ipynb`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![ml flow cheatsheet](images/mlflow-cheatsheet.png)\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vamos a reutilizar el código que ya hemos usado\n",
    "\n",
    "```bash\n",
    "uv add mlflow dagshub jupyter xgboost optuna\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Copiar dataset en una carpeta `data`"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the directory if it doesn't exist\n",
    "!mkdir -p ../data\n",
    "\n",
    "# Download files using curl\n",
    "!curl -o ../data/green_tripdata_2025-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-01.parquet\n",
    "!curl -o ../data/green_tripdata_2025-02.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-02.parquet"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importar las librerías necesarias y definir función para importar los datos"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train = read_dataframe('../data/green_tripdata_2025-01.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2025-02.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Feature Engineering"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One Hot Encoding"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categorical = ['PU_DO']  #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir el `tracking URI` y el nombre del experimento"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "\n",
    "dagshub.init(url=\"<url/del/repo>\", mlflow=True)\n",
    "\n",
    "MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(experiment_name=\"nyc-taxi-experiment\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir los `dataset` como objetos de `mlflow` para poderlos trackear"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2025-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2025-02\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Subir los dataset al storage que nos brinda `dagshub`"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora vamos a entrenar un modelo `xgboost`\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import pathlib"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir los `dataset` a trabajar."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir la función objetivo"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# Definir la función objetivo para Optuna\n",
    "#    - Recibe un `trial`, que se usa para proponer hiperparámetros.\n",
    "#    - Entrena un modelo con esos hiperparámetros.\n",
    "#    - Calcula la métrica de validación (RMSE) y la retorna (Optuna la minimizará).\n",
    "#    - Abrimos un run anidado de MLflow para registrar cada trial.\n",
    "# ------------------------------------------------------------\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    # Hiperparámetros MUETREADOS por Optuna en CADA trial.\n",
    "    # Nota: usamos log=True para emular rangos log-uniformes (similar a loguniform).\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", math.exp(-3), 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\",   math.exp(-5), math.exp(-1), log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", math.exp(-6), math.exp(-1), log=True),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", math.exp(-1), math.exp(3), log=True),\n",
    "        \"objective\": \"reg:squarederror\",  # Fijo (podrías moverlo fuera si quieres)\n",
    "        \"seed\": 42,                       # Fijo para reproducibilidad\n",
    "    }\n",
    "\n",
    "    # 💡 Si quisieras, podrías tener un dict de parámetros fijos FUERA de la función\n",
    "    #    y aquí mezclarlo con los sugeridos por trial:\n",
    "    #    params = {**fixed_params, **sampled_params}\n",
    "\n",
    "    # Run anidado para dejar rastro de cada trial en MLflow\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"xgboost\")  # etiqueta informativa\n",
    "        mlflow.log_params(params)                  # registra hiperparámetros del trial\n",
    "\n",
    "        # Entrenamiento con early stopping en el conjunto de validación\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, \"validation\")],\n",
    "            early_stopping_rounds=10,\n",
    "        )\n",
    "\n",
    "        # Guardar el modelo del trial como artefacto en MLflow\n",
    "        mlflow.xgboost.log_model(booster, artifact_path=\"model\")\n",
    "\n",
    "        # Predicción y métrica en validación\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        # Registrar la métrica principal\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Optuna minimiza el valor retornado\n",
    "    return rmse"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definir el espacio de búsqueda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Crear el estudio de Optuna\n",
    "#    - Usamos TPE (Tree-structured Parzen Estimator) como sampler.\n",
    "#    - direction=\"minimize\" porque queremos minimizar el RMSE.\n",
    "# ------------------------------------------------------------\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar la optimización (n_trials = número de intentos)\n",
    "#    - Cada trial ejecuta la función objetivo con un set distinto de hiperparámetros.\n",
    "#    - Abrimos un run \"padre\" para agrupar toda la búsqueda.\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"XGBoost Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperparámetros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    # Asegurar tipos/campos fijos (por claridad y consistencia)\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"xgboost\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7) Entrenar un modelo FINAL con los mejores hiperparámetros\n",
    "    #    (normalmente lo harías sobre train+val o con CV; aquí mantenemos el patrón original)\n",
    "    # --------------------------------------------------------\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, \"validation\")],\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "\n",
    "    # Evaluar y registrar la métrica final en validación\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8) Guardar artefactos adicionales (p. ej. el preprocesador)\n",
    "    # --------------------------------------------------------\n",
    "    pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_params",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora vamos a registrar el mejor modelo en el `model registry` y usarlo para hacer predicciones"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_id = input(\"Ingrese el run_id\")\n",
    "run_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=run_uri,\n",
    "    name=\"nyc-taxi-model\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "client.update_registered_model(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    description=\"Model registry for the NYC Taxi Time Prediction Project\",\n",
    ")\n",
    "\n",
    "new_alias = \"champion\"\n",
    "date = datetime.today()\n",
    "model_version = \"1\"\n",
    "\n",
    "# create \"champion\" alias for version 1 of model \"nyc-taxi-model\"\n",
    "client.set_registered_model_alias(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    alias=new_alias,\n",
    "    version=model_version\n",
    ")\n",
    "\n",
    "client.update_model_version(\n",
    "    name=\"nyc-taxi-model\",\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_alias} on {date}\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_name = \"nyc-taxi-model\"\n",
    "alias = \"champion\"\n",
    "\n",
    "model_uri = f\"models:/{model_name}@{alias}\"\n",
    "\n",
    "champion_version = mlflow.pyfunc.load_model(\n",
    "    model_uri=model_uri\n",
    ")\n",
    "\n",
    "champion_version.predict(X_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tarea y actividad en clase.\n",
    "\n",
    "1. Hacer merge de la rama que trabajamos a main.\n",
    "2. Crear una nueva rama que se llame `feat: tarea 5`.\n",
    "3. Crear un nuevo `jupyter-notebook` llamado `challenger-experiments.ipynb` en la rama creada anteriormente\n",
    "4. Hacer dos `parent experiments` con `Gradient Boost` y `Random Forest` regressors en donde cada uno tenga `child experiments` con búsqueda de hyper-parámetros. Puede usar cualquier libreraría con la que se sienta cómodo: `hyperopt`, `optuna`, `scikit-learn` (Grid Search, Random Search, Halving Search etc)\n",
    "5. Registrar el modelo con la mejor métrica de los obtenidos en dichos experimentos en el `model registry` en el mismo modelo ya previamente creado `nyc-taxi-model`.\n",
    "6. Asígnele el alias `challenger`\n",
    "7. Descargue en la carpeta `data` el conjunto de datos correspondiente a marzo del 2024\n",
    "8. Guardela en el `storage` disponible de `mlflow`\n",
    "9. Use ese conjunto de datos para probarlo sobre los modelos con el alias `champion` y `challenger`\n",
    "10. Obtenga la métrica de cada modelo\n",
    "11. Decida si el nuevo modelo `challenger` debe ser promovido a `champion` o no. Use los criterios que usted como Data Scientis considere relevantes y justifique la respuesta.\n",
    "12. Abrir un `PR` con los cambios hechos en la rama `feat: tarea 5` hacia la rama `main`.\n",
    "\n",
    "\n",
    "Habrá dos entregas divididas de la siguiente manera:\n",
    "\n",
    "1. **Trabajo en clase hoy Jueves 16 de Octubre de 2025.** Para esta entrega, hacer un commit con el siguiente mensaje `feat: entrega trabajo en clase` con los avances realizados en clase.\n",
    "\n",
    "2. **Tarea: Martes 21 de Octubre de 2025 a las 19:55.** Esta entrega debe contener todo lo descrito anteriormente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
